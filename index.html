<html><head><style>table, th, td { border: 1px solid black; vertical-align:top; padding: 3px} table {table-layout:fixed} td {word-wrap:break-word} th{background-color: DodgerBlue; color: white;}</style><script>function hideAll(){console.log("hideAll")}function showme(e){console.log("showme");var l,n=e.substring(7),o=document.getElementsByName("data");for(l=0;l<o.length;l++)o[l].style.display="none";var t=document.getElementsByName("summary");for(l=0;l<t.length;l++)t[l].style.display="none";document.getElementById(n).style.display="block"}</script></head><body onload="hideAll();"><div style="display: table-cell; width: 140px"><div><a href="#" id="anchor_ppc" onclick="showme(this.id);">PPC SUMMARY</a></div><div><a href="#" id="anchor_x86" onclick="showme(this.id);">X86 SUMMARY</a></div><div><a href="#" id="anchor_ppcx86" onclick="showme(this.id);">FULL SUMMARY</a></div><div>=============</div><div><a href="#" id="anchor_accumulopipe" onclick="showme(this.id);">ACCUMULO</a></div><div><a href="#" id="anchor_ambaripipe" onclick="showme(this.id);">AMBARI</a></div><div><a href="#" id="anchor_atlaspipe" onclick="showme(this.id);">ATLAS</a></div><div><a href="#" id="anchor_falconpipe" onclick="showme(this.id);">FALCON</a></div><div><a href="#" id="anchor_flumepipe" onclick="showme(this.id);">FLUME</a></div><div><a href="#" id="anchor_hadoop-lzo" onclick="showme(this.id);">HADOOP-LZO</a></div><div><a href="#" id="anchor_hadoop-master" onclick="showme(this.id);">HADOOP</a></div><div><a href="#" id="anchor_hbasepipe" onclick="showme(this.id);">HBASE</a></div><div><a href="#" id="anchor_hivepipe" onclick="showme(this.id);">HIVE</a></div><div><a href="#" id="anchor_kafkapipe" onclick="showme(this.id);">KAFKA</a></div><div><a href="#" id="anchor_knoxpipe" onclick="showme(this.id);">KNOX</a></div><div><a href="#" id="anchor_metronpipe" onclick="showme(this.id);">METRON</a></div><div><a href="#" id="anchor_nifi-master" onclick="showme(this.id);">NIFI</a></div><div><a href="#" id="anchor_ooziepipe" onclick="showme(this.id);">OOZIE</a></div><div><a href="#" id="anchor_phoenixpipe" onclick="showme(this.id);">PHOENIX</a></div><div><a href="#" id="anchor_pigpipe" onclick="showme(this.id);">PIG</a></div><div><a href="#" id="anchor_rangerpipe" onclick="showme(this.id);">RANGER</a></div><div><a href="#" id="anchor_sliderpipe" onclick="showme(this.id);">SLIDER</a></div><div><a href="#" id="anchor_sparkpipe" onclick="showme(this.id);">SPARK</a></div><div><a href="#" id="anchor_sqooppipe" onclick="showme(this.id);">SQOOP</a></div><div><a href="#" id="anchor_stormpipe" onclick="showme(this.id);">STORM</a></div><div><a href="#" id="anchor_tezpipe" onclick="showme(this.id);">TEZ</a></div><div><a href="#" id="anchor_zeppelinpipe" onclick="showme(this.id);">ZEPPELIN</a></div><div><a href="#" id="anchor_zookeeperpipe" onclick="showme(this.id);">ZOOKEEPER</a></div></div><div style="display: table-cell"><div style="display:none" id="accumulopipe" name="data"><h2><center>ACCUMULO</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1697</div><div>Failed Count : 0</div><div>Skipped Count : 6</div><div>Duration : 25 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: cdd8c9ee35c47963fa91bb702c6a4465237146c5</div><div>Last Run: 1 day, 5 hr</div></td><td><div>Total Count : 1697</div><div>Failed Count : 2</div><div>Skipped Count : 6</div><div>Duration : 40 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: cdd8c9ee35c47963fa91bb702c6a4465237146c5</div><div>Last Run: 1 day, 5 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</li></div></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol><div><li>test timed out after 60000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="ambaripipe" name="data"><h2><center>AMBARI</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 5273</div><div>Failed Count : 8</div><div>Skipped Count : 83</div><div>Duration : 4 hr 31 min</div><div>Branch Details: origin/trunk</div><div>Last Revision: 9f6612cb190196ed8d646781bb3d5e0c836fe9d2</div><div>Last Run: 1 day, 1 hr</div></td><td><div>Total Count : 5502</div><div>Failed Count : 0</div><div>Skipped Count : 83</div><div>Duration : 2 hr 52 min</div><div>Branch Details: origin/trunk</div><div>Last Revision: 9f6612cb190196ed8d646781bb3d5e0c836fe9d2</div><div>Last Run: 1 day, 1 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/aborted.png" align="top" style="width: 16px; height: 16px;"></img>ABORTED</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>ABORTED</div><div>ABORTED</div><div>ABORTED</div><div>ABORTED</div><div>ABORTED</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div><div>FAILURE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="atlaspipe" name="data"><h2><center>ATLAS</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 771</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 19 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: afbc6975b3eb0ece492f26f508792cf363ad2211</div><div>Last Run: 7 days, 11 hr</div></td><td><div>Total Count : 771</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 7 hr 5 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 6770091aa172576d398e4980f0dacbea65f733ea</div><div>Last Run: 11 hr, 09 min</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="falconpipe" name="data"><h2><center>FALCON</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1002</div><div>Failed Count : 4</div><div>Skipped Count : 0</div><div>Duration : 24 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 1a5b4f6a509187498a267b0e375c6a065f947af5</div><div>Last Run: 22 hr, 43 min</div></td><td><div>Total Count : 1000</div><div>Failed Count : 2</div><div>Skipped Count : 7</div><div>Duration : 42 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 1a5b4f6a509187498a267b0e375c6a065f947af5</div><div>Last Run: 22 hr, 43 min</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.falcon.update.UpdateHelperTest.testIsEntityACLUpdated</li></div><div><li>org.apache.falcon.update.UpdateHelperTest.testIsEntityLateProcessUpdated</li></div><div><li>org.apache.falcon.update.UpdateHelperTest.testIsEntityUpdated</li></div><div><li>org.apache.falcon.update.UpdateHelperTest.testShouldUpdateAffectedEntities</li></div></ol></td><td><ol><div><li>org.apache.falcon.entity.v0.EntityGraphTest.initConfigStore</li></div><div><li>org.apache.falcon.notification.service.SchedulerServiceTest.testDeRegistration</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>Parent path is not a directory: /var/lib/jenkins/workspace/falconpipe/common/target/falcon/tmp-hadoop-jenkins/jail-fs/testCluster/projects/falcon/staging/falcon/workflows/process/sample</li></div><div><li>Parent path is not a directory: /var/lib/jenkins/workspace/falconpipe/common/target/falcon/tmp-hadoop-jenkins/jail-fs/testCluster/projects/falcon/staging/falcon/workflows/process/sample</li></div><div><li>Parent path is not a directory: /var/lib/jenkins/workspace/falconpipe/common/target/falcon/tmp-hadoop-jenkins/jail-fs/testCluster/projects/falcon/staging/falcon/workflows/process/sample</li></div><div><li>Parent path is not a directory: /var/lib/jenkins/workspace/falconpipe/common/target/falcon/tmp-hadoop-jenkins/jail-fs/testCluster/projects/falcon/staging/falcon/workflows/process/sample</li></div></ol></td><td><ol><div><li>Unable to restore configurations for entity type PROCESS</li></div><div><li>expected [1] but found [null]</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.falcon.update.UpdateHelperTest.testIsEntityACLUpdated</div></li><li><div>org.apache.falcon.update.UpdateHelperTest.testIsEntityLateProcessUpdated</div></li><li><div>org.apache.falcon.update.UpdateHelperTest.testIsEntityUpdated</div></li><li><div>org.apache.falcon.update.UpdateHelperTest.testShouldUpdateAffectedEntities</div></li></ol></td><td><ol><li><div>org.apache.falcon.entity.v0.EntityGraphTest.initConfigStore</div></li><li><div>org.apache.falcon.notification.service.SchedulerServiceTest.testDeRegistration</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>ABORTED</div><div>UNSTABLE</div><div>ABORTED</div></td></tr></tbody></table></div><div style="display:none" id="flumepipe" name="data"><h2><center>FLUME</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1181</div><div>Failed Count : 0</div><div>Skipped Count : 6</div><div>Duration : 46 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: d1f24f56ce9714bb3e1edc671da290c75a17dead</div><div>Last Run: 2 days, 0 hr</div></td><td><div>Total Count : 1207</div><div>Failed Count : 0</div><div>Skipped Count : 6</div><div>Duration : 1 hr 6 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: d1f24f56ce9714bb3e1edc671da290c75a17dead</div><div>Last Run: 2 days, 0 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="hadoop-lzo" name="data"><h2><center>HADOOP-LZO</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 27</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 0 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: f1deea9a313f4017dd5323cb8bbb3732c1aaccc5</div><div>Last Run: 1 day, 22 hr</div></td><td><div>Total Count : 27</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 0 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: f1deea9a313f4017dd5323cb8bbb3732c1aaccc5</div><div>Last Run: 1 day, 22 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="hadoop-master" name="data"><h2><center>HADOOP</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 19207</div><div>Failed Count : 17</div><div>Skipped Count : 1202</div><div>Duration : 8 hr 24 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: 8110d6a0d59e7dc2ddb25fa424fab188c5e9ce35</div><div>Last Run: 2 days, 10 hr</div></td><td><div>Total Count : 18937</div><div>Failed Count : 421</div><div>Skipped Count : 1213</div><div>Duration : 14 hr 33 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: edf9445708ffb7a9e59cb933e049b540f99add1e</div><div>Last Run: 19 hr, 12 min</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.hadoop.crypto.key.kms.server.TestKMS.testWebHDFSProxyUserKerb</li></div><div><li>org.apache.hadoop.crypto.key.kms.server.TestKMS.testWebHDFSProxyUserSimple</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testMultipleVolFailuresOnNode</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testDataNodeReconfigureWithVolumeFailures</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testDirectoryScannerInFederatedCluster</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore.org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess</li></div></ol></td><td><ol><div><li>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverMultipleZKfcs</li></div><div><li>org.apache.hadoop.crypto.key.kms.server.TestKMS.testWebHDFSProxyUserKerb</li></div><div><li>org.apache.hadoop.crypto.key.kms.server.TestKMS.testWebHDFSProxyUserSimple</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210.testMultipleDatanodeFailure56</li></div><div><li>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210.testIdempotentCloseWithFailedStreams</li></div><div><li>org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.testUpgradeFromRel1BBWImage</li></div><div><li>org.apache.hadoop.hdfs.TestDatanodeReport.testDatanodeReportMissingBlock</li></div><div><li>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</li></div><div><li>org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend</li></div><div><li>org.apache.hadoop.hdfs.TestLocalDFS.testWorkingDirectory</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeSync.testSyncForDiscontinuousMissingLogs</li></div><div><li>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean.testStorageTypeStatsWhenStorageFailed</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean.testStorageTypeStatsJMX</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID.testUUIDRegeneration</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testSuccessiveVolumeFailures</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testMultipleVolFailuresOnNode</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testDataNodeReconfigureWithVolumeFailures</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testVolFailureStatsPreservedOnNNRestart</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testThrottling</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation.testTmpSpaceReserve</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testRaceDeleteUpdater</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testRaceDeleteCurrentDirUpdater</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testFailoverRightBeforeCommitSynchronization</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testUpdatePipeline</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.net.TestNetworkTopology.testInvalidNetworkTopologiesNotCachedInHdfs</li></div><div><li>org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults</li></div><div><li>org.apache.hadoop.fs.TestDFSIO.org.apache.hadoop.fs.TestDFSIO</li></div><div><li>org.apache.hadoop.fs.TestFileSystem.testFs</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testCreateOp</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testMkdir</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testList</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testRead</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testDelete</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testMRFlow</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testRename</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testAppendOp</li></div><div><li>org.apache.hadoop.fs.slive.TestSlive.testTruncateOp</li></div><div><li>org.apache.hadoop.hdfs.TestNNBench.testNNBenchCreateReadAndDelete</li></div><div><li>org.apache.hadoop.hdfs.TestNNBench.testNNBenchCreateAndRename</li></div><div><li>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithBlockCompression</li></div><div><li>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithRecordCompression</li></div><div><li>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithNoCompression</li></div><div><li>org.apache.hadoop.ipc.TestMRCJCSocketFactory.testSocketFactory</li></div><div><li>org.apache.hadoop.mapred.TestClusterMRNotification.testMR</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMRConfig</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestCollect.testCollect</li></div><div><li>org.apache.hadoop.mapred.TestComparators.testDefaultMRComparator</li></div><div><li>org.apache.hadoop.mapred.TestComparators.testUserMRComparator</li></div><div><li>org.apache.hadoop.mapred.TestComparators.testUserValueGroupingComparator</li></div><div><li>org.apache.hadoop.mapred.TestComparators.testBakedUserComparator</li></div><div><li>org.apache.hadoop.mapred.TestComparators.testAllUserComparators</li></div><div><li>org.apache.hadoop.mapred.TestFieldSelection.testFieldSelection</li></div><div><li>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithoutPathFilterWithGlob</li></div><div><li>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithPathFilterWithoutGlob</li></div><div><li>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithoutPathFilterWithoutGlob</li></div><div><li>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithPathFilterWithGlob</li></div><div><li>org.apache.hadoop.mapred.TestFileOutputFormat.testCustomFile</li></div><div><li>org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob</li></div><div><li>org.apache.hadoop.mapred.TestJavaSerialization.testWriteToSequencefile</li></div><div><li>org.apache.hadoop.mapred.TestJobCleanup.org.apache.hadoop.mapred.TestJobCleanup</li></div><div><li>org.apache.hadoop.mapred.TestJobCounters.org.apache.hadoop.mapred.TestJobCounters</li></div><div><li>org.apache.hadoop.mapred.TestJobCounters.org.apache.hadoop.mapred.TestJobCounters</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestJobSysDirWithDFS.testWithDFS</li></div><div><li>org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testGzip</li></div><div><li>org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestLineRecordReaderJobs.testDefaultRecordDelimiters</li></div><div><li>org.apache.hadoop.mapred.TestLineRecordReaderJobs.testCustomRecordDelimiters</li></div><div><li>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobFilesOption</li></div><div><li>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobEncryptedIntermediateData</li></div><div><li>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobArchivesOption</li></div><div><li>org.apache.hadoop.mapred.TestLocalJobSubmission.testJobMaxMapConfig</li></div><div><li>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobLibjarsOption</li></div><div><li>org.apache.hadoop.mapred.TestLocalMRNotification.testMR</li></div><div><li>org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter.testAbort</li></div><div><li>org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter.testCommitter</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testUberMode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMROpportunisticMaps.testHalfOpportunisticMaps</li></div><div><li>org.apache.hadoop.mapred.TestMROpportunisticMaps.testAllOpportunisticMaps</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testTimelineServiceStartInMiniCluster</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled</li></div><div><li>org.apache.hadoop.mapred.TestMapOutputType.testNoMismatch</li></div><div><li>org.apache.hadoop.mapred.TestMapOutputType.testValueMismatch</li></div><div><li>org.apache.hadoop.mapred.TestMapOutputType.testKeyMismatch</li></div><div><li>org.apache.hadoop.mapred.TestMapProgress.testMapProgress</li></div><div><li>org.apache.hadoop.mapred.TestMapRed.testNullKeys</li></div><div><li>org.apache.hadoop.mapred.TestMapRed.testSmallInput</li></div><div><li>org.apache.hadoop.mapred.TestMapRed.testBiggerInput</li></div><div><li>org.apache.hadoop.mapred.TestMapRed.testCompression</li></div><div><li>org.apache.hadoop.mapred.TestMapRed.testMapred</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRBringup.testBringUp</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRChildTask.org.apache.hadoop.mapred.TestMiniMRChildTask</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRClasspath.testClassPath</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRClasspath.testExternalWritable</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRClientCluster.org.apache.hadoop.mapred.TestMiniMRClientCluster</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRClientCluster.org.apache.hadoop.mapred.TestMiniMRClientCluster</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers.testMultipleSpills</li></div><div><li>org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers.testDistinctUsers</li></div><div><li>org.apache.hadoop.mapred.TestMultiFileInputFormat.testFormatWithLessPathsThanSplits</li></div><div><li>org.apache.hadoop.mapred.TestMultiFileInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations</li></div><div><li>org.apache.hadoop.mapred.TestMultipleTextOutputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestNetworkedJob.testGetJobStatus</li></div><div><li>org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient</li></div><div><li>org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob</li></div><div><li>org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReporter.testReporterProgressForMRJob</li></div><div><li>org.apache.hadoop.mapred.TestReporter.testStatusLimit</li></div><div><li>org.apache.hadoop.mapred.TestReporter.testReporterProgressForMapOnlyJob</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileAsBinaryInputFormat.testBinary</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testcheckOutputSpecsForbidRecordCompression</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testPercentFilter</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testMD5Filter</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testRegexFilter</li></div><div><li>org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath.testJobWithDFS</li></div><div><li>org.apache.hadoop.mapred.TestTaskCommit.testCommitFail</li></div><div><li>org.apache.hadoop.mapred.TestTaskCommit.testTaskCleanupDoesNotCommit</li></div><div><li>org.apache.hadoop.mapred.TestTextOutputFormat.testCompress</li></div><div><li>org.apache.hadoop.mapred.TestTextOutputFormat.testFormatWithCustomSeparator</li></div><div><li>org.apache.hadoop.mapred.TestTextOutputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testNodeLabelExp</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodesDifferentRack</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodesDefaultRack</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityAny</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMProfiler</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMStandardEnvWithCustomLibPath</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMStandardEnvWithDefaultLibPath</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testJobPriority</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testCustomAMRMResourceType</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityNode</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityRack</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityInvalid</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMRMemoryRequestOverriding</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodes</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityNodeDefaultRack</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testSendJobConf</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testGetHSDelegationToken</li></div><div><li>org.apache.hadoop.mapred.TestYARNRunner.testAMRMemoryRequest</li></div><div><li>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testJobControl</li></div><div><li>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testAddingDependingJob</li></div><div><li>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testJobState</li></div><div><li>org.apache.hadoop.mapred.jobcontrol.TestLocalJobControl.testLocalJobControlDataCopy</li></div><div><li>org.apache.hadoop.mapred.join.TestDatamerge.testNestedJoin</li></div><div><li>org.apache.hadoop.mapred.join.TestDatamerge.testEmptyJoin</li></div><div><li>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleOuterJoin</li></div><div><li>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleOverride</li></div><div><li>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleInnerJoin</li></div><div><li>org.apache.hadoop.mapred.lib.TestChainMapReduce.testChain</li></div><div><li>org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.testBasicUnixComparator</li></div><div><li>org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithCounters</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithCounters</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithoutCounters</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithoutCounters</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testRuntimeExRun</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testOKRun</li></div><div><li>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testIOExRun</li></div><div><li>org.apache.hadoop.mapred.lib.aggregate.TestAggregates.testAggregates</li></div><div><li>org.apache.hadoop.mapred.pipes.TestPipesNonJavaInputFormat.testFormat</li></div><div><li>org.apache.hadoop.mapreduce.TestChild.testChild</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobName</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobSubmissionSpecsAndFiles</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testMapCleanup</li></div><div><li>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testJobSuccessCleanup</li></div><div><li>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testReduceCleanup</li></div><div><li>org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner</li></div><div><li>org.apache.hadoop.mapreduce.TestValueIterReset.testValueIterReset</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.org.apache.hadoop.mapreduce.security.TestBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.testJobHistoryData</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDefaultProfiler</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDifferentProfilers</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestRMNMInfo.testRMNMInfo</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testPreserveUseNonEmptyDir</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.yarn.sls.TestSLSRunner.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShellWithNodeLabels.testDSShellWithNodeLabelExpression</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraints</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraints</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyE2E</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testE2ETokenSwap</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClient</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClientNoCleanupOnStop</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E.org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByReservationId[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testReservationDelete[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByInvalidTimeInterval[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testUpdateReservation[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeIntervalContainingNoReservations[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testCreateReservation[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeInterval[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByReservationId[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testReservationDelete[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByInvalidTimeInterval[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testUpdateReservation[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeIntervalContainingNoReservations[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testCreateReservation[FAIR]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeInterval[FAIR]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.testStartLocalizer</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.testNoExitCodeFromPrivilegedOperation</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.testDirStructure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testNodeHealthService</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testContainerResourceIncreaseIsSynchronizedWithRMResync</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testKillContainersOnResync</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testKillContainersOnShutdown</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExitFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeLocalizationFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testChangeContainerResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitCommit</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testForcefulShutdownSignal</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testGracefulShutdownSignal</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessAutoCommit</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testOutputThreadDumpSignal</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeProcessFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExitSuccess</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerRestart</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testImmediateKill</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitWithMultipleFiles</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchOnConfigurationError</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testDelayedKill</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitWithCustomPattern</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitForCase</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExit</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitForExt</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testDirectoryCleanupOnNewlyCreatedStateStore</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizerHeartbeatWhenAppCleaningUp</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testRecovery</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizationHeartbeat</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizationInit</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testDownloadingResourcesOnContainerKill</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalResourcePath</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testParallelDownloadAttemptsForPrivateResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testPublicResourceInitializesLocalDir</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testFailedPublicResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testParallelDownloadAttemptsForPublicResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLocalFileDeletionOnDiskFull</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerMonitor</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStopQueuedContainer</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartMultipleContainers</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartAndQueueMultipleContainers</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testQueueShedding</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartOpportunistcsWhenOppQueueIsFull</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testPromotionOfOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testPauseOpportunisticForGuaranteedContainer</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testContainerDeQueuedAfterAMKill</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testContainerUpdateExecTypeGuaranteedToOpportunistic</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOpportunisticForGuaranteedContainer</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogsWithNewAPI</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogsWithOldAPI</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenApplicationCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</li></div><div><li>org.apache.hadoop.yarn.server.TestDiskFailures.testLocalDirsFailures</li></div><div><li>org.apache.hadoop.yarn.server.TestDiskFailures.testDirFailuresOnStartup</li></div><div><li>org.apache.hadoop.yarn.server.TestDiskFailures.testLogDirsFailures</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://localhost:35264/kms/v1/keys?doAs=foo1</li></div><div><li>org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://localhost:36196/kms/v1/keys?doAs=foo1</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>Timed out waiting for /test2 to reach 3 replicas</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li> Expected to find 'localhost:34346: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34346: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:46597: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:46597: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39886: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39886: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:43027: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43027: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:40174: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:40174: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39278: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39278: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>initTable on TestDynamoDBMetadataStore: com.amazonaws.services.dynamodbv2.model.AmazonDynamoDBException: The request processing has failed because of an unknown error, exception or failure. (Service: AmazonDynamoDBv2; Status Code: 500; Error Code: InternalFailure; Request ID: 6dbe9212-c440-477b-b26b-a29b53727306): The request processing has failed because of an unknown error, exception or failure.</li></div><div><li>Unexpected number of YARN_CONTAINER_FINISHED event published. expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory.&lt;init&gt;(LogAggregationFileControllerFactory.java:68)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerLogsPage$ContainersLogsBlock.&lt;init&gt;(ContainerLogsPage.java:100)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAcc</li></div></ol></td><td><ol><div><li>Unable to become active. Local node did not get an opportunity to do so from ZooKeeper, or the local node took too long to transition to active.</li></div><div><li>org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://localhost:36100/kms/v1/keys?doAs=foo1</li></div><div><li>org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://localhost:42394/kms/v1/keys?doAs=foo1</li></div><div><li>expected:&lt;1520411891613&gt; but was:&lt;1520411892768&gt;</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>Error replaying edit log at offset 660.  Expected transaction ID was 12
Recent opcode offsets: 409 516 643 660</li></div><div><li>Failed to recover lease of /1kb-multiple-checksum-blocks-64-16</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>write timedout too late in 1216 ms.</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>test timed out after 20000 milliseconds</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>Test resulted in an unexpected exit</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>expected:&lt;6&gt; but was:&lt;5&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>Timed out waiting for /test1 to reach 2 replicas</li></div><div><li>Timed out waiting for /test1 to reach 2 replicas</li></div><div><li>Throttle is too permissive</li></div><div><li>Wrong reserve space for Tmp  expected:&lt;200&gt; but was:&lt;1000&gt;</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 09:24:49,393

"IPC Client (970535245) connection to localhost/127.0.0.1:46545 from jenkins" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1016)
        at org.apache.hadoop.i</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 10:22:04,283

"IPC Server listener on 35511" daemon prio=5 tid=1545 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
 </li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 10:29:02,939

"qtp389012793-4654" daemon prio=5 tid=4654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitN</li></div><div><li>inode should complete in ~60000 ms.
Expected: is &lt;true&gt;
     but: was &lt;false&gt;</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>After waiting the operation updatePipeline still has not taken effect on NN yet</li></div><div><li> Expected to find 'localhost:35506: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35506: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:46415: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:46415: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:43356: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43356: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:46752: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:46752: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35793: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35793: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:44992: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:44992: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testCreateOp(TestSlive.java:290)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeM</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testMkdir(TestSlive.java:503)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMeth</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testList(TestSlive.java:460)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMetho</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testRead(TestSlive.java:434)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMetho</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testDelete(TestSlive.java:381)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMet</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.testMRFlow(TestSlive.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.Del</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testRename(TestSlive.java:402)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMet</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testAppendOp(TestSlive.java:532)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeM</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.fs.slive.TestSlive.runOperationOk(TestSlive.java:354)
	at org.apache.hadoop.fs.slive.TestSlive.testTruncateOp(TestSlive.java:554)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.Nativ</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Wrong FS: file:/var/lib/jenkins/workspace/hadoop-master/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/input, expected: hdfs://localhost:38878</li></div><div><li>Wrong FS: file:/var/lib/jenkins/workspace/hadoop-master/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/input, expected: hdfs://localhost:38878</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Job failed</li></div><div><li>Job failed</li></div><div><li>Job failed</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Job failed</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Threw exception:java.net.ConnectException: Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Threw exception:java.net.ConnectException: Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Block compression should be allowed for SequenceFileAsBinaryOutputFormat:Caught java.net.ConnectException</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Wrong FS: file:/var/lib/jenkins/workspace/hadoop-master/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/org.apache.hadoop.mapred.TestUserDefinedCounters/input, expected: hdfs://localhost:38878</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityInvalid(TestYARNRunner.java:764)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorI</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>
mRClientProtocol.getDelegationToken(&lt;any&gt;);
Never wanted here:
-&gt; at org.apache.hadoop.mapred.TestYARNRunner.testGetHSDelegationToken(TestYARNRunner.java:449)
But invoked here:
-&gt; at org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:250)
</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Could not create staging directory. </li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From in-ibmibm662.persistent.co.in/10.53.17.125 to localhost:38878 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestValueIterReset.testValueIterReset(TestValueIterReset.java:549)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.j</li></div><div><li>Could not create staging directory. </li></div><div><li>test timed out after 90000 milliseconds</li></div><div><li>test timed out after 150000 milliseconds</li></div><div><li>test timed out after 150000 milliseconds</li></div><div><li>Node "in-ibmibm662.persistent.co.in:38913" should be RUNNING</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>src and dst file does not match at 0 between HdfsNamedFileStatus{path=hdfs://localhost:35757/testdir/srcdat/file0; isDirectory=false; length=102400; replication=2; blocksize=1024; modification_time=1520452228424; access_time=1520452224402; owner=u1; group=g1; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} and HdfsNamedFileStatus{path=hdfs://localhost:</li></div><div><li>File group ownership should match expected:&lt;[g0]&gt; but was:&lt;[supergroup]&gt;</li></div><div><li>/ by zero</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>test timed out after 90000 milliseconds</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>unable to create new native thread</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCa</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invo</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>java.net.BindException: Problem binding to [0.0.0.0:8049] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException</li></div><div><li>java.net.BindException: Problem binding to [0.0.0.0:8049] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException</li></div><div><li>Index: 0, Size: 0</li></div><div><li>Index: 0, Size: 0</li></div><div><li>Index: 0, Size: 0</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:49:56,890

"IPC Server handler 17 on 33386" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionO</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:50:09,579

"qtp2074826904-593" daemon prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at su</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:50:21,878

"qtp2074826904-593" daemon prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at su</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:50:34,427

"qtp2074826904-593" daemon prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at su</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:50:47,187

"IPC Server handler 9 on 44053" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionOb</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:50:59,739

"IPC Server handler 9 on 44053" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionOb</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:51:12,292

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:51:25,623

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:51:38,906

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:51:51,832

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:52:05,202

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:52:18,045

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:52:31,526

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 01:52:45,283

"pool-129-thread-1"  prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(A</li></div><div><li>No space available in any of the local directories.</li></div><div><li>Unexpected exception org.apache.hadoop.util.DiskChecker$DiskErrorException: No space available in any of the local directories.</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Node health status reported unhealthy</li></div><div><li>The container should create a subDir named currentUser: jenkinsunder localDir/usercache</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>Metrics source NodeManagerMetrics already exists!</li></div><div><li>/var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown/tmpDir/start_file.txt (No such file or directory)</li></div><div><li>expected:&lt;50&gt; but was:&lt;-1000&gt;</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>/var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/TestContainerManager-localDir/nmPrivate doesn't exist!!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>AppDir /var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/TestContainerManager-localDir/usercache/nobody/appcache/application_0_0000 doesn't exist!!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>expected:&lt;0&gt; but was:&lt;-1000&gt;</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>No space available in any of the local directories.</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-03-07 12:04:47,677

"process reaper" daemon prio=10 tid=32 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueu</li></div><div><li>
Wanted but not invoked:
nodeStatusUpdater.reportException(&lt;any&gt;);
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchOnConfigurationError(TestContainerLaunch.java:1606)
Actually, there were zero interactions with this mock.
</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>No space available in any of the local directories.</li></div><div><li>No space available in any of the local directories.</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>No space available in any of the local directories.</li></div><div><li>No space available in any of the local directories.</li></div><div><li>
Wanted but not invoked:
localFs.mkdir(
    /var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService/0/usercache,
    rwxr-xr-x,
    true
);
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResour</li></div><div><li>test timed out after 20000 milliseconds</li></div><div><li>No space available in any of the local directories.</li></div><div><li>
Wanted but not invoked:
containerExecutor.startLocalizer(
    &lt;Capturing argument&gt;
);
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizationHeartbeat(TestResourceLocalizationService.java:955)
Actually, there were zero interactions with this mock.
</li></div><div><li>
Wanted but not invoked:
localFs.mkdir(
    /var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService/0/usercache,
    rwxr-xr-x,
    true
);
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResour</li></div><div><li>test timed out after 20000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>Index: 0, Size: 0</li></div><div><li>
Wanted but not invoked:
localFs.mkdir(
    /var/lib/jenkins/workspace/hadoop-master/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService/0/filecache,
    rwxr-xr-x,
    true
);
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResour</li></div><div><li>test timed out after 20000 milliseconds</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testParallelDownloadAttemptsForPublicResource(TestResourceLocalizationService.java:2262)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>
deletionService.delete(
    &lt;File deletion matcher&gt;
);
Wanted 2 times:
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyLocalFileDeletion(TestLogAggregationService.java:228)
But was 1 time:
-&gt; at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregationPostCleanUp(AppLogAggregat</li></div><div><li>ProcessStartFile doesn't exist!</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>expected:&lt;RUNNING&gt; but was:&lt;DONE&gt;</li></div><div><li>expected:&lt;6&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>expected:&lt;RUNNING&gt; but was:&lt;DONE&gt;</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>ContainerState is not correct (timedout)</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOpportunisticForGuaranteedContainer(TestContainerSchedulerQueuing.java:544)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(N</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory.&lt;init&gt;(LogAggregationFileControllerFactory.java:68)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerLogsPage$ContainersLogsBlock.&lt;init&gt;(ContainerLogsPage.java:100)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAcc</li></div><div><li>No space available in any of the local directories.</li></div><div><li>No space available in any of the local directories.</li></div><div><li>expected:&lt;0&gt; but was:&lt;8192&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1024&gt;</li></div><div><li>expected:&lt;1000&gt; but was:&lt;0&gt;</li></div><div><li>Number of nm-local-dirs is wrong. expected:&lt;4&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Number of nm-log-dirs is wrong. expected:&lt;4&gt; but was:&lt;0&gt;</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testDirectoryScannerInFederatedCluster</div></li><li><div>org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore.org.apache.hadoop.fs.s3a.s3guard.TestDynamoDBMetadataStore</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</div></li></ol></td><td><ol><li><div>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverMultipleZKfcs</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210.testMultipleDatanodeFailure56</div></li><li><div>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210.testIdempotentCloseWithFailedStreams</div></li><li><div>org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.testUpgradeFromRel1BBWImage</div></li><li><div>org.apache.hadoop.hdfs.TestDatanodeReport.testDatanodeReportMissingBlock</div></li><li><div>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</div></li><li><div>org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend</div></li><li><div>org.apache.hadoop.hdfs.TestLocalDFS.testWorkingDirectory</div></li><li><div>org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeSync.testSyncForDiscontinuousMissingLogs</div></li><li><div>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean.testStorageTypeStatsWhenStorageFailed</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean.testStorageTypeStatsJMX</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeUUID.testUUIDRegeneration</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testSuccessiveVolumeFailures</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testVolFailureStatsPreservedOnNNRestart</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testThrottling</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestSpaceReservation.testTmpSpaceReserve</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testRaceDeleteUpdater</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testRaceDeleteCurrentDirUpdater</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testFailoverRightBeforeCommitSynchronization</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testUpdatePipeline</div></li><li><div>org.apache.hadoop.net.TestNetworkTopology.testInvalidNetworkTopologiesNotCachedInHdfs</div></li><li><div>org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults</div></li><li><div>org.apache.hadoop.fs.TestDFSIO.org.apache.hadoop.fs.TestDFSIO</div></li><li><div>org.apache.hadoop.fs.TestFileSystem.testFs</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testCreateOp</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testMkdir</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testList</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testRead</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testDelete</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testMRFlow</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testRename</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testAppendOp</div></li><li><div>org.apache.hadoop.fs.slive.TestSlive.testTruncateOp</div></li><li><div>org.apache.hadoop.hdfs.TestNNBench.testNNBenchCreateReadAndDelete</div></li><li><div>org.apache.hadoop.hdfs.TestNNBench.testNNBenchCreateAndRename</div></li><li><div>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithBlockCompression</div></li><li><div>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithRecordCompression</div></li><li><div>org.apache.hadoop.io.TestSequenceFileMergeProgress.testMergeProgressWithNoCompression</div></li><li><div>org.apache.hadoop.ipc.TestMRCJCSocketFactory.testSocketFactory</div></li><li><div>org.apache.hadoop.mapred.TestClusterMRNotification.testMR</div></li><li><div>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</div></li><li><div>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMRConfig</div></li><li><div>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart</div></li><li><div>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</div></li><li><div>org.apache.hadoop.mapred.TestCollect.testCollect</div></li><li><div>org.apache.hadoop.mapred.TestComparators.testDefaultMRComparator</div></li><li><div>org.apache.hadoop.mapred.TestComparators.testUserMRComparator</div></li><li><div>org.apache.hadoop.mapred.TestComparators.testUserValueGroupingComparator</div></li><li><div>org.apache.hadoop.mapred.TestComparators.testBakedUserComparator</div></li><li><div>org.apache.hadoop.mapred.TestComparators.testAllUserComparators</div></li><li><div>org.apache.hadoop.mapred.TestFieldSelection.testFieldSelection</div></li><li><div>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithoutPathFilterWithGlob</div></li><li><div>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithPathFilterWithoutGlob</div></li><li><div>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithoutPathFilterWithoutGlob</div></li><li><div>org.apache.hadoop.mapred.TestFileInputFormatPathFilter.testWithPathFilterWithGlob</div></li><li><div>org.apache.hadoop.mapred.TestFileOutputFormat.testCustomFile</div></li><li><div>org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob</div></li><li><div>org.apache.hadoop.mapred.TestJavaSerialization.testWriteToSequencefile</div></li><li><div>org.apache.hadoop.mapred.TestJobCleanup.org.apache.hadoop.mapred.TestJobCleanup</div></li><li><div>org.apache.hadoop.mapred.TestJobCounters.org.apache.hadoop.mapred.TestJobCounters</div></li><li><div>org.apache.hadoop.mapred.TestJobCounters.org.apache.hadoop.mapred.TestJobCounters</div></li><li><div>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</div></li><li><div>org.apache.hadoop.mapred.TestJobName.testComplexName</div></li><li><div>org.apache.hadoop.mapred.TestJobSysDirWithDFS.testWithDFS</div></li><li><div>org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testGzip</div></li><li><div>org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</div></li><li><div>org.apache.hadoop.mapred.TestLineRecordReaderJobs.testDefaultRecordDelimiters</div></li><li><div>org.apache.hadoop.mapred.TestLineRecordReaderJobs.testCustomRecordDelimiters</div></li><li><div>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobFilesOption</div></li><li><div>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobEncryptedIntermediateData</div></li><li><div>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobArchivesOption</div></li><li><div>org.apache.hadoop.mapred.TestLocalJobSubmission.testJobMaxMapConfig</div></li><li><div>org.apache.hadoop.mapred.TestLocalJobSubmission.testLocalJobLibjarsOption</div></li><li><div>org.apache.hadoop.mapred.TestLocalMRNotification.testMR</div></li><li><div>org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter.testAbort</div></li><li><div>org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter.testCommitter</div></li><li><div>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testUberMode</div></li><li><div>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</div></li><li><div>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</div></li><li><div>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</div></li><li><div>org.apache.hadoop.mapred.TestMROpportunisticMaps.testHalfOpportunisticMaps</div></li><li><div>org.apache.hadoop.mapred.TestMROpportunisticMaps.testAllOpportunisticMaps</div></li><li><div>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling</div></li><li><div>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</div></li><li><div>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testTimelineServiceStartInMiniCluster</div></li><li><div>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled</div></li><li><div>org.apache.hadoop.mapred.TestMapOutputType.testNoMismatch</div></li><li><div>org.apache.hadoop.mapred.TestMapOutputType.testValueMismatch</div></li><li><div>org.apache.hadoop.mapred.TestMapOutputType.testKeyMismatch</div></li><li><div>org.apache.hadoop.mapred.TestMapProgress.testMapProgress</div></li><li><div>org.apache.hadoop.mapred.TestMapRed.testNullKeys</div></li><li><div>org.apache.hadoop.mapred.TestMapRed.testSmallInput</div></li><li><div>org.apache.hadoop.mapred.TestMapRed.testBiggerInput</div></li><li><div>org.apache.hadoop.mapred.TestMapRed.testCompression</div></li><li><div>org.apache.hadoop.mapred.TestMapRed.testMapred</div></li><li><div>org.apache.hadoop.mapred.TestMerge.testMerge</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRBringup.testBringUp</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRChildTask.org.apache.hadoop.mapred.TestMiniMRChildTask</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRClasspath.testClassPath</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRClasspath.testExternalWritable</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRClientCluster.org.apache.hadoop.mapred.TestMiniMRClientCluster</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRClientCluster.org.apache.hadoop.mapred.TestMiniMRClientCluster</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers.testMultipleSpills</div></li><li><div>org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers.testDistinctUsers</div></li><li><div>org.apache.hadoop.mapred.TestMultiFileInputFormat.testFormatWithLessPathsThanSplits</div></li><li><div>org.apache.hadoop.mapred.TestMultiFileInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations</div></li><li><div>org.apache.hadoop.mapred.TestMultipleTextOutputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestNetworkedJob.testGetJobStatus</div></li><li><div>org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient</div></li><li><div>org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob</div></li><li><div>org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner</div></li><li><div>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</div></li><li><div>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</div></li><li><div>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</div></li><li><div>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</div></li><li><div>org.apache.hadoop.mapred.TestReporter.testReporterProgressForMRJob</div></li><li><div>org.apache.hadoop.mapred.TestReporter.testStatusLimit</div></li><li><div>org.apache.hadoop.mapred.TestReporter.testReporterProgressForMapOnlyJob</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileAsBinaryInputFormat.testBinary</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testcheckOutputSpecsForbidRecordCompression</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testPercentFilter</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testMD5Filter</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileInputFilter.testRegexFilter</div></li><li><div>org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath.testJobWithDFS</div></li><li><div>org.apache.hadoop.mapred.TestTaskCommit.testCommitFail</div></li><li><div>org.apache.hadoop.mapred.TestTaskCommit.testTaskCleanupDoesNotCommit</div></li><li><div>org.apache.hadoop.mapred.TestTextOutputFormat.testCompress</div></li><li><div>org.apache.hadoop.mapred.TestTextOutputFormat.testFormatWithCustomSeparator</div></li><li><div>org.apache.hadoop.mapred.TestTextOutputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testNodeLabelExp</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodesDifferentRack</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodesDefaultRack</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityAny</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMProfiler</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMStandardEnvWithCustomLibPath</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMStandardEnvWithDefaultLibPath</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testJobPriority</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testCustomAMRMResourceType</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityNode</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityRack</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityInvalid</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMRMemoryRequestOverriding</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityMultipleNodes</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testResourceRequestLocalityNodeDefaultRack</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testSendJobConf</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testGetHSDelegationToken</div></li><li><div>org.apache.hadoop.mapred.TestYARNRunner.testAMRMemoryRequest</div></li><li><div>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testJobControl</div></li><li><div>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testAddingDependingJob</div></li><li><div>org.apache.hadoop.mapred.jobcontrol.TestJobControl.testJobState</div></li><li><div>org.apache.hadoop.mapred.jobcontrol.TestLocalJobControl.testLocalJobControlDataCopy</div></li><li><div>org.apache.hadoop.mapred.join.TestDatamerge.testNestedJoin</div></li><li><div>org.apache.hadoop.mapred.join.TestDatamerge.testEmptyJoin</div></li><li><div>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleOuterJoin</div></li><li><div>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleOverride</div></li><li><div>org.apache.hadoop.mapred.join.TestDatamerge.testSimpleInnerJoin</div></li><li><div>org.apache.hadoop.mapred.lib.TestChainMapReduce.testChain</div></li><li><div>org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.testBasicUnixComparator</div></li><li><div>org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithCounters</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithCounters</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithoutCounters</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultipleOutputs.testWithoutCounters</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testRuntimeExRun</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testOKRun</div></li><li><div>org.apache.hadoop.mapred.lib.TestMultithreadedMapRunner.testIOExRun</div></li><li><div>org.apache.hadoop.mapred.lib.aggregate.TestAggregates.testAggregates</div></li><li><div>org.apache.hadoop.mapred.pipes.TestPipesNonJavaInputFormat.testFormat</div></li><li><div>org.apache.hadoop.mapreduce.TestChild.testChild</div></li><li><div>org.apache.hadoop.mapreduce.TestMRJobClient.testJobName</div></li><li><div>org.apache.hadoop.mapreduce.TestMRJobClient.testJobSubmissionSpecsAndFiles</div></li><li><div>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</div></li><li><div>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</div></li><li><div>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testMapCleanup</div></li><li><div>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testJobSuccessCleanup</div></li><li><div>org.apache.hadoop.mapreduce.TestMapperReducerCleanup.testReduceCleanup</div></li><li><div>org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner</div></li><li><div>org.apache.hadoop.mapreduce.TestValueIterReset.testValueIterReset</div></li><li><div>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.org.apache.hadoop.mapreduce.security.TestBinaryTokenFile</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.testJobHistoryData</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDefaultProfiler</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDifferentProfilers</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestRMNMInfo.testRMNMInfo</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testPreserveUseNonEmptyDir</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</div></li><li><div>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</div></li><li><div>org.apache.hadoop.yarn.sls.TestSLSRunner.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</div></li><li><div>org.apache.hadoop.streaming.TestSymLink.testSymLink</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShellWithNodeLabels.testDSShellWithNodeLabelExpression</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitExecType[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFit[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClient[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerDemotion[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithBlacklist[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithInvalidNodeLabels[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientNoMatchingRequests[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientOnAMRMTokenRollOver[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchingFitInferredRack[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testWaitFor[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAskWithNodeLabels[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerPromotion[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientMatchStorage[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMContainerPromotionAndDemotionWithAutoUpdate[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocationWithBlacklist[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithSaslEncryption[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraints</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraints</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyE2E</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testE2ETokenSwap</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClient</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClientNoCleanupOnStop</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E.org.apache.hadoop.yarn.client.api.impl.TestOpportunisticContainerAllocationE2E</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByReservationId[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testReservationDelete[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByInvalidTimeInterval[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testUpdateReservation[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeIntervalContainingNoReservations[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testCreateReservation[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeInterval[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByReservationId[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testReservationDelete[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByInvalidTimeInterval[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testUpdateReservation[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeIntervalContainingNoReservations[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testCreateReservation[FAIR]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestYarnClientWithReservation.testListReservationsByTimeInterval[FAIR]</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.testStartLocalizer</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.testNoExitCodeFromPrivilegedOperation</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.testDirStructure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testNodeHealthService</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testContainerResourceIncreaseIsSynchronizedWithRMResync</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testKillContainersOnResync</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testKillContainersOnShutdown</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExitFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeLocalizationFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testChangeContainerResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitCommit</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testForcefulShutdownSignal</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testGracefulShutdownSignal</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessAutoCommit</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testOutputThreadDumpSignal</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeProcessFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExitSuccess</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerRestart</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testImmediateKill</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitWithMultipleFiles</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchOnConfigurationError</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testDelayedKill</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitWithCustomPattern</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitForCase</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExit</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testErrorLogOnContainerExitForExt</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testDirectoryCleanupOnNewlyCreatedStateStore</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizerHeartbeatWhenAppCleaningUp</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testRecovery</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizationHeartbeat</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalizationInit</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testDownloadingResourcesOnContainerKill</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testLocalResourcePath</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testParallelDownloadAttemptsForPrivateResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testPublicResourceInitializesLocalDir</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testFailedPublicResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testParallelDownloadAttemptsForPublicResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLocalFileDeletionOnDiskFull</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerMonitor</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStopQueuedContainer</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartMultipleContainers</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartAndQueueMultipleContainers</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testQueueShedding</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testStartOpportunistcsWhenOppQueueIsFull</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testPromotionOfOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testPauseOpportunisticForGuaranteedContainer</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testContainerDeQueuedAfterAMKill</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testContainerUpdateExecTypeGuaranteedToOpportunistic</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOpportunisticForGuaranteedContainer</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogsWithNewAPI</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogsWithOldAPI</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenApplicationCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</div></li><li><div>org.apache.hadoop.yarn.server.TestDiskFailures.testLocalDirsFailures</div></li><li><div>org.apache.hadoop.yarn.server.TestDiskFailures.testDirFailuresOnStartup</div></li><li><div>org.apache.hadoop.yarn.server.TestDiskFailures.testLogDirsFailures</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>FAILURE</div><div>FAILURE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="hbasepipe" name="data"><h2><center>HBASE</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 4476</div><div>Failed Count : 1</div><div>Skipped Count : 46</div><div>Duration : 2 hr 48 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 0732ef5ebfea8e254d4a5dad6fe16ecccca3b799</div><div>Last Run: 6 days, 11 hr</div></td><td><div>Total Count : 4488</div><div>Failed Count : 3</div><div>Skipped Count : 46</div><div>Duration : 4 hr 19 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 0732ef5ebfea8e254d4a5dad6fe16ecccca3b799</div><div>Last Run: 6 days, 11 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.testGetProcedure</li></div></ol></td><td><ol><div><li>org.apache.hadoop.hbase.io.asyncfs.TestFanOutOneBlockAsyncDFSOutput.testHeartbeat</li></div><div><li>org.apache.hadoop.hbase.master.assignment.TestMergeTableRegionsProcedure.testMergeWithoutPONR</li></div><div><li>org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.testLargeSmallIsolation</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>expected procedure result</li></div></ol></td><td><ol><div><li>java.io.IOException: Bad response ERROR_CHECKSUM for block BP-1371232331-172.17.0.4-1519928077557:blk_1073741830_1010 from datanode /127.0.0.1:37387</li></div><div><li>expected:&lt;false&gt; but was:&lt;true&gt;</li></div><div><li>expected:&lt;20&gt; but was:&lt;19&gt;</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.hadoop.hbase.master.procedure.TestProcedureAdmin.testGetProcedure</div></li></ol></td><td><ol><li><div>org.apache.hadoop.hbase.io.asyncfs.TestFanOutOneBlockAsyncDFSOutput.testHeartbeat</div></li><li><div>org.apache.hadoop.hbase.master.assignment.TestMergeTableRegionsProcedure.testMergeWithoutPONR</div></li><li><div>org.apache.hadoop.hbase.master.cleaner.TestHFileCleaner.testLargeSmallIsolation</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="hivepipe" name="data"><h2><center>HIVE</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 6861</div><div>Failed Count : 14</div><div>Skipped Count : 221</div><div>Duration : 3 hr 41 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 7cb31c03052b815665b3231f2e513b9e65d3ff8c</div><div>Last Run: 1 day, 10 hr</div></td><td><div>Total Count : 6818</div><div>Failed Count : 11</div><div>Skipped Count : 220</div><div>Duration : 18 hr 43 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: a0b262875cd22120ab04ef598cf2bf6ce6163935</div><div>Last Run: 8 days, 10 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.testOutputFormat</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div><div><li>org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForPartitionedMmTable</li></div><div><li>org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testInsertOverwriteForPartitionedMmTable</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan1</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan2</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan3</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan4</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan5</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan6</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapPlan1</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapPlan2</li></div><div><li>org.apache.hadoop.hive.ql.exec.tez.TestWorkloadManager.testQueueing</li></div><div><li>org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.testStringLikeMultiByte</li></div></ol></td><td><ol><div><li>org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.testOutputFormat</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan1</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan2</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan3</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan4</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan5</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapRedPlan6</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapPlan1</li></div><div><li>org.apache.hadoop.hive.ql.exec.TestExecDriver.testMapPlan2</li></div><div><li>org.apache.hadoop.hive.ql.exec.vector.expressions.TestVectorStringExpressions.testStringLikeMultiByte</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.testOutputFormat(TestHCatMultiOutputFormat.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeM</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:797)
	at org.apac</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForPartitionedMmTable(TestTxnCommandsForMmTable.java:359)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForPartitionedMmTable(TestTxnCommandsForMmTable.java:359)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div></ol></td><td><ol><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hive.hcatalog.mapreduce.TestHCatMultiOutputFormat.testOutputFormat(TestHCatMultiOutputFormat.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeM</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:797)
	at org.apac</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.hadoop.hive.ql.TestTxnCommandsForMmTable.testInsertOverwriteForPartitionedMmTable</div></li><li><div>org.apache.hadoop.hive.ql.TestTxnCommandsForOrcMmTable.testInsertOverwriteForPartitionedMmTable</div></li><li><div>org.apache.hadoop.hive.ql.exec.tez.TestWorkloadManager.testQueueing</div></li></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="kafkapipe" name="data"><h2><center>KAFKA</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 8730</div><div>Failed Count : 1</div><div>Skipped Count : 7</div><div>Duration : 1 hr 16 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: 5d87b926d50823004a96a97062e0866d92d07b41</div><div>Last Run: 5 days, 20 hr</div></td><td><div>Total Count : 8705</div><div>Failed Count : 0</div><div>Skipped Count : 7</div><div>Duration : 1 hr 32 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: 1d8ed875db6ec624cdb8bc15ec677729a42fc13a</div><div>Last Run: 13 days, 7 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol><div><li>kafka.api.ClientIdQuotaTest.testThrottledProducerConsumer</li></div></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol><div><li>java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</li></div></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>kafka.api.ClientIdQuotaTest.testThrottledProducerConsumer</div></li></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>ABORTED</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="knoxpipe" name="data"><h2><center>KNOX</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 947</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 13 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 21ac567db07c3f2196dfb41cb7bf9bbb786801a2</div><div>Last Run: 2 days, 1 hr</div></td><td><div>Total Count : 947</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 16 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 21ac567db07c3f2196dfb41cb7bf9bbb786801a2</div><div>Last Run: 2 days, 1 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="metronpipe" name="data"><h2><center>METRON</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1613</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 44 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: b48ab93c65f04a7e25f1c0de20c260582fed30bc</div><div>Last Run: 3 days, 0 hr</div></td><td><div>Total Count : 1613</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 53 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: b48ab93c65f04a7e25f1c0de20c260582fed30bc</div><div>Last Run: 3 days, 0 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="nifi-master" name="data"><h2><center>NIFI</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 5236</div><div>Failed Count : 0</div><div>Skipped Count : 131</div><div>Duration : 35 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 5041bea773c47b0b16b0a0e713d13c16f0cd66b6</div><div>Last Run: 7 days, 7 hr</div></td><td><div>Total Count : 5237</div><div>Failed Count : 0</div><div>Skipped Count : 131</div><div>Duration : 51 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: dfd5339690cab8612f4a97a82e99499c2484569f</div><div>Last Run: 4 hr, 05 min</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>UNSTABLE</div><div>SUCCESS</div><div>UNSTABLE</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="ooziepipe" name="data"><h2><center>OOZIE</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 2092</div><div>Failed Count : 33</div><div>Skipped Count : 2</div><div>Duration : 1 hr 44 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 9e662c7350d64ddfa41e62882ce3328216f29dff</div><div>Last Run: 2 days, 13 hr</div></td><td><div>Total Count : 1977</div><div>Failed Count : 4</div><div>Skipped Count : 0</div><div>Duration : 2 hr 49 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 9e662c7350d64ddfa41e62882ce3328216f29dff</div><div>Last Run: 2 days, 11 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCredentialsSkip</li></div><div><li>org.apache.oozie.jms.TestDefaultConnectionContext.testThreadLocalSession</li></div><div><li>org.apache.oozie.jms.TestHCatMessageHandler.testDropEventTypeMessage</li></div><div><li>org.apache.oozie.jms.TestHCatMessageHandler.testCacheUpdateByMessage</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectors</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectorsNegative</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectors</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobSuccessEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuspendEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsAnd</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobFailureEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testConnectionDrop</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsNegative</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsOr</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuccessEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionWaitingEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobFailureEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionStartEvent</li></div><div><li>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobStartedEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMetEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMetEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectorsNegative</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMetEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMissEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectors</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMissEvent</li></div><div><li>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMissEvent</li></div><div><li>org.apache.oozie.service.TestJMSAccessorService.testConnectionRetry</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testPartitionDependency</li></div><div><li>org.apache.oozie.util.graph.TestGraphGenerator.testGraphWithManyNodes</li></div><div><li>org.apache.oozie.util.graph.TestGraphGenerator.testSimpleGraphPng</li></div><div><li>org.apache.oozie.util.graph.TestGraphGenerator.testSimpleGraphSvg</li></div><div><li>org.apache.oozie.util.graph.TestGraphGenerator.testGraphWithDecisionForkJoin</li></div></ol></td><td><ol><div><li>org.apache.oozie.action.hadoop.TestHiveActionExecutor.testHiveAction</li></div><div><li>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</li></div><div><li>org.apache.oozie.action.hadoop.TestPigActionExecutor.testExecutionStatsWithMaxStatsSizeLimit</li></div><div><li>org.apache.oozie.action.hadoop.TestPigActionExecutor.testUdfPig</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>JA020: Could not load credentials of type [abc] with name [abcname]]; perhaps it was not defined in oozie-site.xml?</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestDefaultConnectionContext.testThreadLocalSession(TestDefaultConnectionContext.java:74)
</li></div><div><li>Could not create Transport. Reason: javax.management.InstanceAlreadyExistsException: org.apache.activemq:type=Broker,brokerName=localhost</li></div><div><li>Could not create Transport. Reason: javax.management.InstanceAlreadyExistsException: org.apache.activemq:type=Broker,brokerName=localhost</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectors(TestJMSJobEventListener.java:544)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectorsNegative(TestJMSJobEventListener.java:568)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectors(TestJMSJobEventListener.java:239)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobSuccessEvent(TestJMSJobEventListener.java:477)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuspendEvent(TestJMSJobEventListener.java:214)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsAnd(TestJMSJobEventListener.java:316)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobFailureEvent(TestJMSJobEventListener.java:517)
</li></div><div><li>org.apache.activemq:type=Broker,brokerName=localhost</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsNegative(TestJMSJobEventListener.java:262)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsOr(TestJMSJobEventListener.java:289)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuccessEvent(TestJMSJobEventListener.java:143)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionWaitingEvent(TestJMSJobEventListener.java:403)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobFailureEvent(TestJMSJobEventListener.java:180)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionStartEvent(TestJMSJobEventListener.java:439)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobStartedEvent(TestJMSJobEventListener.java:108)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMetEvent(TestJMSSLAEventListener.java:382)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMetEvent(TestJMSSLAEventListener.java:292)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectorsNegative(TestJMSSLAEventListener.java:261)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMetEvent(TestJMSSLAEventListener.java:332)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMissEvent(TestJMSSLAEventListener.java:103)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectors(TestJMSSLAEventListener.java:231)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMissEvent(TestJMSSLAEventListener.java:143)
</li></div><div><li>java.lang.NullPointerException
	at org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMissEvent(TestJMSSLAEventListener.java:191)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.service.TestJMSAccessorService.testConnectionRetry(TestJMSAccessorService.java:183)
</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testPartitionDependency(TestPartitionDependencyManagerEhcache.java:47)
</li></div><div><li>java.util.concurrent.ExecutionException: java.lang.NullPointerException</li></div><div><li>Render and write PNG failed for graph-workflow-simple.xml: java.util.concurrent.TimeoutException</li></div><div><li>Render and write SVG failed: java.util.concurrent.TimeoutException</li></div><div><li>java.util.concurrent.TimeoutException</li></div></ol></td><td><ol><div><li>YARN App state for app application_1520267476940_0003 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1520267916480_0001 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1520266563973_0005 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1520266563973_0015 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.oozie.action.hadoop.TestJavaActionExecutor.testCredentialsSkip</div></li><li><div>org.apache.oozie.jms.TestDefaultConnectionContext.testThreadLocalSession</div></li><li><div>org.apache.oozie.jms.TestHCatMessageHandler.testDropEventTypeMessage</div></li><li><div>org.apache.oozie.jms.TestHCatMessageHandler.testCacheUpdateByMessage</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectors</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testCoordinatorActionSelectorsNegative</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectors</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobSuccessEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuspendEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsAnd</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorJobFailureEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testConnectionDrop</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsNegative</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testWorkflowJobSelectorsOr</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobSuccessEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionWaitingEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobFailureEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnCoordinatorActionStartEvent</div></li><li><div>org.apache.oozie.jms.TestJMSJobEventListener.testOnWorkflowJobStartedEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMetEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMetEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectorsNegative</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMetEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAStartMissEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testSLAJobSelectors</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLAEndMissEvent</div></li><li><div>org.apache.oozie.jms.TestJMSSLAEventListener.testOnSLADurationMissEvent</div></li><li><div>org.apache.oozie.service.TestJMSAccessorService.testConnectionRetry</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testPartitionDependency</div></li><li><div>org.apache.oozie.util.graph.TestGraphGenerator.testGraphWithManyNodes</div></li><li><div>org.apache.oozie.util.graph.TestGraphGenerator.testSimpleGraphPng</div></li><li><div>org.apache.oozie.util.graph.TestGraphGenerator.testSimpleGraphSvg</div></li><li><div>org.apache.oozie.util.graph.TestGraphGenerator.testGraphWithDecisionForkJoin</div></li></ol></td><td><ol><li><div>org.apache.oozie.action.hadoop.TestHiveActionExecutor.testHiveAction</div></li><li><div>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</div></li><li><div>org.apache.oozie.action.hadoop.TestPigActionExecutor.testExecutionStatsWithMaxStatsSizeLimit</div></li><li><div>org.apache.oozie.action.hadoop.TestPigActionExecutor.testUdfPig</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="phoenixpipe" name="data"><h2><center>PHOENIX</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1657</div><div>Failed Count : 0</div><div>Skipped Count : 5</div><div>Duration : 7 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 1a226ed3e6ac4a56658acbac4da0d518af343ee2</div><div>Last Run: 6 days, 1 hr</div></td><td><div>Total Count : 1657</div><div>Failed Count : 0</div><div>Skipped Count : 5</div><div>Duration : 12 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 1a226ed3e6ac4a56658acbac4da0d518af343ee2</div><div>Last Run: 6 days, 1 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="pigpipe" name="data"><h2><center>PIG</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 895</div><div>Failed Count : 20</div><div>Skipped Count : 0</div><div>Duration : 25 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: 1fcd7196e21117eb4c365f26adc19210f63fbdec</div><div>Last Run: 6 days, 23 hr</div></td><td><div>Total Count : 895</div><div>Failed Count : 20</div><div>Skipped Count : 0</div><div>Duration : 27 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: 1fcd7196e21117eb4c365f26adc19210f63fbdec</div><div>Last Run: 6 days, 23 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.pig.test.TestBuiltin.testRANDOMWithJob</li></div><div><li>org.apache.pig.test.TestBuiltin.testSFPig</li></div><div><li>org.apache.pig.test.TestBuiltin.testUniqueID</li></div><div><li>org.apache.pig.test.TestLoad.testCommaSeparatedString3</li></div><div><li>org.apache.pig.test.TestLoad.testCommaSeparatedString5</li></div><div><li>org.apache.pig.test.TestLoad.testLoadRemoteAbsScheme</li></div><div><li>org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194</li></div><div><li>org.apache.pig.test.TestPigServer.testRegisterRemoteScript</li></div><div><li>org.apache.pig.test.TestSchema.testEnabledDisambiguationPassesForDupeAliases</li></div><div><li>org.apache.pig.test.TestSchema.testSchemaSerialization</li></div><div><li>org.apache.pig.test.TestSchema.testDisabledDisambiguationContainsNoColonsForNestedSchema</li></div><div><li>org.apache.pig.test.TestSchema.testDisabledDisambiguationContainsNoColons</li></div><div><li>org.apache.pig.test.TestStore.testStore</li></div><div><li>org.apache.pig.test.TestStore.testStoreComplexDataWithNull</li></div><div><li>org.apache.pig.test.TestStore.testBinStorageGetSchema</li></div><div><li>org.apache.pig.test.TestStore.testStoreComplexData</li></div><div><li>org.apache.pig.test.TestStore.testSetStoreSchema</li></div><div><li>org.apache.pig.test.TestStore.testSuccessFileCreation1</li></div><div><li>org.apache.pig.test.TestStore.testCleanupOnFailureMultiStore</li></div><div><li>org.apache.pig.test.TestStore.testEmptyPartFileCreation</li></div></ol></td><td><ol><div><li>org.apache.pig.test.TestBuiltin.testRANDOMWithJob</li></div><div><li>org.apache.pig.test.TestBuiltin.testSFPig</li></div><div><li>org.apache.pig.test.TestBuiltin.testUniqueID</li></div><div><li>org.apache.pig.test.TestLoad.testCommaSeparatedString3</li></div><div><li>org.apache.pig.test.TestLoad.testCommaSeparatedString5</li></div><div><li>org.apache.pig.test.TestLoad.testLoadRemoteAbsScheme</li></div><div><li>org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194</li></div><div><li>org.apache.pig.test.TestPigServer.testRegisterRemoteScript</li></div><div><li>org.apache.pig.test.TestSchema.testEnabledDisambiguationPassesForDupeAliases</li></div><div><li>org.apache.pig.test.TestSchema.testSchemaSerialization</li></div><div><li>org.apache.pig.test.TestSchema.testDisabledDisambiguationContainsNoColonsForNestedSchema</li></div><div><li>org.apache.pig.test.TestSchema.testDisabledDisambiguationContainsNoColons</li></div><div><li>org.apache.pig.test.TestStore.testStore</li></div><div><li>org.apache.pig.test.TestStore.testStoreComplexDataWithNull</li></div><div><li>org.apache.pig.test.TestStore.testBinStorageGetSchema</li></div><div><li>org.apache.pig.test.TestStore.testStoreComplexData</li></div><div><li>org.apache.pig.test.TestStore.testSetStoreSchema</li></div><div><li>org.apache.pig.test.TestStore.testSuccessFileCreation1</li></div><div><li>org.apache.pig.test.TestStore.testCleanupOnFailureMultiStore</li></div><div><li>org.apache.pig.test.TestStore.testEmptyPartFileCreation</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>Unable to open iterator for alias B</li></div><div><li>Input path does not exist: hdfs://localhost:45776/user/jenkins/testSFPig-output.txt</li></div><div><li>Unable to open iterator for alias B</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194(TestLocalRearrange.java:231)
</li></div><div><li>Unable to open iterator for alias b</li></div><div><li>Unable to open iterator for alias C</li></div><div><li>Unable to open iterator for alias c</li></div><div><li>Unable to open iterator for alias F</li></div><div><li>Unable to open iterator for alias E</li></div><div><li>File /tmp/TestStore/TestStore-output--8870149238083785419.txt does not exist.</li></div><div><li>File /tmp/TestStore/TestStore-output--3648501044956356676.txt does not exist.</li></div><div><li>Checking binstorage getSchema output</li></div><div><li>File /tmp/TestStore/TestStore-output--6140104366719219848.txt does not exist.</li></div><div><li>Checking if file /tmp/TestStore/_commitJob_called does  exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>Checking if _SUCCESS file exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>Checking if file /tmp/TestStore/_setupTask_called1 does  exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>File /tmp/TestStore/TestStore-output--6971012850789807919.txt_1 does not exist.</li></div></ol></td><td><ol><div><li>Unable to open iterator for alias B</li></div><div><li>Input path does not exist: hdfs://localhost:39447/user/jenkins/testSFPig-output.txt</li></div><div><li>Unable to open iterator for alias B</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>Unable to open iterator for alias a</li></div><div><li>junit.framework.AssertionFailedError
	at org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194(TestLocalRearrange.java:231)
</li></div><div><li>Unable to open iterator for alias b</li></div><div><li>Unable to open iterator for alias C</li></div><div><li>Unable to open iterator for alias c</li></div><div><li>Unable to open iterator for alias F</li></div><div><li>Unable to open iterator for alias E</li></div><div><li>File /tmp/TestStore/TestStore-output--7145657669155416259.txt does not exist.</li></div><div><li>File /tmp/TestStore/TestStore-output--118732224428820703.txt does not exist.</li></div><div><li>Checking binstorage getSchema output</li></div><div><li>File /tmp/TestStore/TestStore-output--7008433171014022874.txt does not exist.</li></div><div><li>Checking if file /tmp/TestStore/_commitJob_called does  exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>Checking if _SUCCESS file exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>Checking if file /tmp/TestStore/_setupTask_called1 does  exists in MAPREDUCE mode expected:&lt;true&gt; but was:&lt;false&gt;</li></div><div><li>File /tmp/TestStore/TestStore-output-4367888378110763719.txt_1 does not exist.</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="rangerpipe" name="data"><h2><center>RANGER</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1029</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 14 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 70379200545a8cd859f9f163da4a4327001f84c1</div><div>Last Run: 2 days, 21 hr</div></td><td><div>Total Count : 1029</div><div>Failed Count : 0</div><div>Skipped Count : 2</div><div>Duration : 23 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 70379200545a8cd859f9f163da4a4327001f84c1</div><div>Last Run: 2 days, 21 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>FAILURE</div><div>SUCCESS</div><div>FAILURE</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>FAILURE</div><div>UNSTABLE</div><div>FAILURE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="sliderpipe" name="data"><h2><center>SLIDER</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 607</div><div>Failed Count : 24</div><div>Skipped Count : 13</div><div>Duration : 22 min</div><div>Branch Details: refs/remotes/origin/develop</div><div>Last Revision: 7ee66cd7cc049fecc2d553f5541147702e81a5b0</div><div>Last Run: 6 days, 5 hr</div></td><td><div>Total Count : 607</div><div>Failed Count : 24</div><div>Skipped Count : 13</div><div>Duration : 25 min</div><div>Branch Details: refs/remotes/origin/develop</div><div>Last Revision: 7ee66cd7cc049fecc2d553f5541147702e81a5b0</div><div>Last Run: 6 days, 5 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.slider.agent.actions.TestActionExists.testExistsLiveCluster</li></div><div><li>org.apache.slider.agent.actions.TestActionList.testActionListSuite</li></div><div><li>org.apache.slider.agent.actions.TestActionStatus.testSuite</li></div><div><li>org.apache.slider.agent.freezethaw.TestFreezeCommands.testFreezeCommands</li></div><div><li>org.apache.slider.agent.freezethaw.TestFreezeThawFlexStandaloneAM.testFreezeThawFlexStandaloneAM</li></div><div><li>org.apache.slider.agent.rest.TestStandaloneREST.testStandaloneREST</li></div><div><li>org.apache.slider.agent.standalone.TestBuildStandaloneAM.testBuildCluster</li></div><div><li>org.apache.slider.agent.standalone.TestBuildStandaloneAM.testUpdateCluster</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMDestroy.testStandaloneAMDestroy</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestartWithDefaultRetryWindow</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestart</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestartWithRetryWindow</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAgentAM.testStandaloneAgentAM</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneYarnRegistryAM.testStandaloneYarnRegistryAM</li></div><div><li>org.apache.slider.client.TestDiagnostics.testContainerDiagsNoAppContainer</li></div><div><li>org.apache.slider.client.TestDiagnostics.testContainerDiagsWithAppPackage</li></div><div><li>org.apache.slider.client.TestUpgradeCommandOptions.testAll</li></div><div><li>org.apache.slider.providers.agent.TestAddonPackage.testEchoApplicationAddPackage</li></div><div><li>org.apache.slider.providers.agent.TestAgentAAEcho.testAgentEcho</li></div><div><li>org.apache.slider.providers.agent.TestAgentAMManagementWS.testAgentAMManagementWS</li></div><div><li>org.apache.slider.providers.agent.TestAgentEcho.testAgentEcho</li></div><div><li>org.apache.slider.server.appmaster.TestDelayInContainerLaunch.testDelayInContainerLaunch</li></div><div><li>org.apache.slider.server.appmaster.web.rest.publisher.TestPublisherRestResources.testRestURIs</li></div></ol></td><td><ol><div><li>org.apache.slider.agent.actions.TestActionExists.testExistsLiveCluster</li></div><div><li>org.apache.slider.agent.actions.TestActionList.testActionListSuite</li></div><div><li>org.apache.slider.agent.actions.TestActionStatus.testSuite</li></div><div><li>org.apache.slider.agent.freezethaw.TestFreezeCommands.testFreezeCommands</li></div><div><li>org.apache.slider.agent.freezethaw.TestFreezeThawFlexStandaloneAM.testFreezeThawFlexStandaloneAM</li></div><div><li>org.apache.slider.agent.rest.TestStandaloneREST.testStandaloneREST</li></div><div><li>org.apache.slider.agent.standalone.TestBuildStandaloneAM.testBuildCluster</li></div><div><li>org.apache.slider.agent.standalone.TestBuildStandaloneAM.testUpdateCluster</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMDestroy.testStandaloneAMDestroy</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestartWithDefaultRetryWindow</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestart</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAMRestart.testStandaloneAMRestartWithRetryWindow</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneAgentAM.testStandaloneAgentAM</li></div><div><li>org.apache.slider.agent.standalone.TestStandaloneYarnRegistryAM.testStandaloneYarnRegistryAM</li></div><div><li>org.apache.slider.client.TestDiagnostics.testContainerDiagsNoAppContainer</li></div><div><li>org.apache.slider.client.TestDiagnostics.testContainerDiagsWithAppPackage</li></div><div><li>org.apache.slider.client.TestUpgradeCommandOptions.testAll</li></div><div><li>org.apache.slider.providers.agent.TestAddonPackage.testEchoApplicationAddPackage</li></div><div><li>org.apache.slider.providers.agent.TestAgentAAEcho.testAgentEcho</li></div><div><li>org.apache.slider.providers.agent.TestAgentAMManagementWS.testAgentAMManagementWS</li></div><div><li>org.apache.slider.providers.agent.TestAgentEcho.testAgentEcho</li></div><div><li>org.apache.slider.server.appmaster.TestDelayInContainerLaunch.testDelayInContainerLaunch</li></div><div><li>org.apache.slider.server.appmaster.web.rest.publisher.TestPublisherRestResources.testRestURIs</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>Launch failed with exit code -1</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Application not running: application_1519938882040_0001 state=FAILED </li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Failed on local exception: java.io.FileNotFoundException: http://916f7a38ec45:44283/cluster/app/application_1519938433149_0001; Host Details : local host is: "localhost"; destination host is: "http://916f7a38ec45:44283/cluster/app/application_1519938433149_0001":44283; </li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>assert report.yarnApplicationState == YarnApplicationState.RUNNING
       |      |                                            |
       |      FAILED                                       RUNNING
       applicationId { id: 1 cluster_timestamp: 1519938826451 } user: "jenkins" queue: "default" name: "testkillstandaloneam" host: "N/A" rpc_port: -1 yarn_application_state: FAILED trackingUrl: "http://91</li></div><div><li>Cluster teststandaloneamrestartwithdefaultretrywindow not live after 30000 ms</li></div><div><li>Cluster teststandaloneamrestart not live after 30000 ms</li></div><div><li>Cluster teststandaloneamrestartwithretrywindow not live after 30000 ms</li></div><div><li>assert uri.port in 60000..60010
       |   |            |
       |   36774        [60000, 60001, 60002, 60003, 60004, 60005, 60006, 60007, 60008, 60009, 60010]
       http://916f7a38ec45:36774/cluster/app/application_1519938682897_0001</li></div><div><li>Application not running: application_1519938706339_0001 state=FAILED </li></div><div><li>assert 0 == status
         |  |
         |  -1
         false</li></div><div><li>Launch failed with exit code -1</li></div><div><li>Upgrade command should have failed</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div></ol></td><td><ol><div><li>Launch failed with exit code -1</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Application not running: application_1519939185487_0001 state=FAILED </li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Failed on local exception: java.io.FileNotFoundException: http://b8868a12600e:37466/cluster/app/application_1519939212176_0001; Host Details : local host is: "localhost"; destination host is: "http://b8868a12600e:37466/cluster/app/application_1519939212176_0001":37466; </li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>assert report.yarnApplicationState == YarnApplicationState.RUNNING
       |      |                                            |
       |      FAILED                                       RUNNING
       applicationId { id: 1 cluster_timestamp: 1519938819261 } user: "jenkins" queue: "default" name: "testkillstandaloneam" host: "N/A" rpc_port: -1 yarn_application_state: FAILED trackingUrl: "http://b8</li></div><div><li>Cluster teststandaloneamrestartwithdefaultretrywindow not live after 30000 ms</li></div><div><li>Cluster teststandaloneamrestart not live after 30000 ms</li></div><div><li>Cluster teststandaloneamrestartwithretrywindow not live after 30000 ms</li></div><div><li>assert uri.port in 60000..60010
       |   |            |
       |   41370        [60000, 60001, 60002, 60003, 60004, 60005, 60006, 60007, 60008, 60009, 60010]
       http://b8868a12600e:41370/cluster/app/application_1519938792038_0001</li></div><div><li>Application not running: application_1519938873805_0001 state=FAILED </li></div><div><li>assert 0 == status
         |  |
         |  -1
         false</li></div><div><li>Launch failed with exit code -1</li></div><div><li>Upgrade command should have failed</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div><div><li>Launch failed with exit code 65</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="sparkpipe" name="data"><h2><center>SPARK</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 13628</div><div>Failed Count : 1</div><div>Skipped Count : 667</div><div>Duration : 4 hr 29 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 476a7f026bc45462067ebd39cd269147e84cd641</div><div>Last Run: 7 days, 6 hr</div></td><td><div>Total Count : 15303</div><div>Failed Count : 1</div><div>Skipped Count : 674</div><div>Duration : 6 hr 5 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 476a7f026bc45462067ebd39cd269147e84cd641</div><div>Last Run: 7 days, 6 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</li></div></ol></td><td><ol><div><li>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>Timeout of './bin/spark-submit' '--class' 'org.apache.spark.sql.hive.SparkSQLConfTest' '--name' 'SparkSQLConfTest' '--master' 'local-cluster[2,1,1024]' '--conf' 'spark.ui.enabled=false' '--conf' 'spark.master.rest.enabled=false' '--conf' 'spark.sql.hive.metastore.version=0.12' '--conf' 'spark.sql.hive.metastore.jars=maven' '--driver-java-options' '-Dderby.system.durability=test' 'file:/var/lib/jen</li></div></ol></td><td><ol><div><li>Timeout of './bin/spark-submit' '--class' 'org.apache.spark.sql.hive.SparkSQLConfTest' '--name' 'SparkSQLConfTest' '--master' 'local-cluster[2,1,1024]' '--conf' 'spark.ui.enabled=false' '--conf' 'spark.master.rest.enabled=false' '--conf' 'spark.sql.hive.metastore.version=0.12' '--conf' 'spark.sql.hive.metastore.jars=maven' '--driver-java-options' '-Dderby.system.durability=test' 'file:/var/lib/jen</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>ABORTED</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="sqooppipe" name="data"><h2><center>SQOOP</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 720</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 37 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: a7f5e0d298ffbf8e674bd35ee10f2accc1da5453</div><div>Last Run: 6 days, 0 hr</div></td><td><div>Total Count : 720</div><div>Failed Count : 0</div><div>Skipped Count : 0</div><div>Duration : 41 min</div><div>Branch Details: refs/remotes/origin/trunk</div><div>Last Revision: a7f5e0d298ffbf8e674bd35ee10f2accc1da5453</div><div>Last Run: 6 days, 0 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px; "></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:none" id="stormpipe" name="data"><h2><center>STORM</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1165</div><div>Failed Count : 0</div><div>Skipped Count : 5</div><div>Duration : 22 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 21f4173f25b44eea8b985987afb20c476751a50a</div><div>Last Run: 7 days, 1 hr</div></td><td><div>Total Count : 1165</div><div>Failed Count : 1</div><div>Skipped Count : 5</div><div>Duration : 32 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 21f4173f25b44eea8b985987afb20c476751a50a</div><div>Last Run: 7 days, 1 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol><div><li>org.apache.storm.daemon.drpc.DRPCTest.testGoodBlocking</li></div></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol><div><li>java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.storm.daemon.drpc.DRPCTest.testGoodBlocking(DRPCTest.java:92)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorIm</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol><li><div>org.apache.storm.daemon.drpc.DRPCTest.testGoodBlocking</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>SUCCESS</div><div>SUCCESS</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="tezpipe" name="data"><h2><center>TEZ</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1763</div><div>Failed Count : 1</div><div>Skipped Count : 14</div><div>Duration : 59 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: bb40cf5b8a49833e13760a0ffe566092eb464d88</div><div>Last Run: 6 days, 22 hr</div></td><td><div>Total Count : 1763</div><div>Failed Count : 3</div><div>Skipped Count : 14</div><div>Duration : 1 hr 7 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: bb40cf5b8a49833e13760a0ffe566092eb464d88</div><div>Last Run: 6 days, 22 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.analyzer.TestAnalyzer.testWithATS</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol><div><li>expected:&lt;KILLED&gt; but was:&lt;SUCCEEDED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.tez.analyzer.TestAnalyzer.getDagInfo(TestAnalyzer.java:264)
	at org.apache.tez.analyzer.TestAnalyzer.verify(TestAnalyzer.java:251)
	at org.apache.tez.analyzer.TestAnalyzer.runTests(TestAnalyzer.java:390)
	at org.apac</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li><li><div>org.apache.tez.analyzer.TestAnalyzer.testWithATS</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="zeppelinpipe" name="data"><h2><center>ZEPPELIN</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 650</div><div>Failed Count : 26</div><div>Skipped Count : 5</div><div>Duration : 1 hr 29 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: d90716d4d00f5b83d2bd1f16cadc88118a112f74</div><div>Last Run: 2 days, 15 hr</div></td><td><div>Total Count : 646</div><div>Failed Count : 31</div><div>Skipped Count : 4</div><div>Duration : 6 hr 24 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: c77c549e3f6bfa7b08ebc0bfaacb2bd8719c875f</div><div>Last Run: 1 day, 20 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.configuration.RequestHeaderSizeTest.increased_request_header_size_do_not_cause_413_when_request_size_is_over_8K</li></div><div><li>org.apache.zeppelin.recovery.RecoveryTest.org.apache.zeppelin.recovery.RecoveryTest</li></div><div><li>org.apache.zeppelin.rest.ConfigurationsRestApiTest.org.apache.zeppelin.rest.ConfigurationsRestApiTest</li></div><div><li>org.apache.zeppelin.rest.CredentialsRestApiTest.org.apache.zeppelin.rest.CredentialsRestApiTest</li></div><div><li>org.apache.zeppelin.rest.HeliumRestApiTest.org.apache.zeppelin.rest.HeliumRestApiTest</li></div><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.org.apache.zeppelin.rest.InterpreterRestApiTest</li></div><div><li>org.apache.zeppelin.rest.KnoxRestApiTest.org.apache.zeppelin.rest.KnoxRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookRepoRestApiTest.org.apache.zeppelin.rest.NotebookRepoRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.org.apache.zeppelin.rest.NotebookRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookSecurityRestApiTest.org.apache.zeppelin.rest.NotebookSecurityRestApiTest</li></div><div><li>org.apache.zeppelin.rest.SecurityRestApiTest.org.apache.zeppelin.rest.SecurityRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.org.apache.zeppelin.rest.ZeppelinSparkClusterTest</li></div><div><li>org.apache.zeppelin.socket.NotebookServerTest.org.apache.zeppelin.socket.NotebookServerTest</li></div><div><li>org.apache.zeppelin.helium.HeliumApplicationFactoryTest.testInterpreterUnbindOfNullReplParagraph</li></div><div><li>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testYarnClusterMode</li></div><div><li>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testLocalMode</li></div><div><li>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testYarnClientMode</li></div><div><li>org.apache.zeppelin.notebook.NotebookTest.testPerNoteSessionInterpreter</li></div></ol></td><td><ol><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testCompletion</li></div><div><li>org.apache.zeppelin.rest.ConfigurationsRestApiTest.org.apache.zeppelin.rest.ConfigurationsRestApiTest</li></div><div><li>org.apache.zeppelin.rest.CredentialsRestApiTest.org.apache.zeppelin.rest.CredentialsRestApiTest</li></div><div><li>org.apache.zeppelin.rest.HeliumRestApiTest.org.apache.zeppelin.rest.HeliumRestApiTest</li></div><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.org.apache.zeppelin.rest.InterpreterRestApiTest</li></div><div><li>org.apache.zeppelin.rest.KnoxRestApiTest.org.apache.zeppelin.rest.KnoxRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookRepoRestApiTest.org.apache.zeppelin.rest.NotebookRepoRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.org.apache.zeppelin.rest.NotebookRestApiTest</li></div><div><li>org.apache.zeppelin.rest.NotebookSecurityRestApiTest.org.apache.zeppelin.rest.NotebookSecurityRestApiTest</li></div><div><li>org.apache.zeppelin.rest.SecurityRestApiTest.org.apache.zeppelin.rest.SecurityRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.org.apache.zeppelin.rest.ZeppelinSparkClusterTest</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[3]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[3]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[3]</li></div></ol></td></tr><tr><td>Description</td><td><ol><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;[你好]
&gt; but was:&lt;[??]
&gt;</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Either no interpreter named fake or it is not binded to this note</li></div><div><li>SPARK_HOME is not specified in interpreter-setting for non-local mode, if you specify it in zeppelin-env.sh, please move that into  interpreter setting</li></div><div><li>SPARK_HOME is not specified in interpreter-setting for non-local mode, if you specify it in zeppelin-env.sh, please move that into  interpreter setting</li></div><div><li>SPARK_HOME is not specified in interpreter-setting for non-local mode, if you specify it in zeppelin-env.sh, please move that into  interpreter setting</li></div><div><li>Values should be different. Actual: 781724953</li></div></ol></td><td><ol><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;[你好]
&gt; but was:&lt;[??]
&gt;</li></div><div><li>java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.zeppelin.spark.PySparkInterpreterTest.testCompletion(PySparkInterpreterTest.java:142)
</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>Can not start Zeppelin server</li></div><div><li>/var/lib/jenkins/workspace/zeppelinpipe/zeppelin-zengine/../bin/interpreter.sh: line 235: /var/lib/jenkins/workspace/zeppelinpipe/run/zeppelin-interpreter-spark--f0859ea62fc2.pid: No such file or directory
Warning: Master yarn-cluster is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
06:22:42,255  WARN org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load </li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div><div><li>java.lang.NullPointerException</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol><li><div>org.apache.zeppelin.configuration.RequestHeaderSizeTest.increased_request_header_size_do_not_cause_413_when_request_size_is_over_8K</div></li><li><div>org.apache.zeppelin.recovery.RecoveryTest.org.apache.zeppelin.recovery.RecoveryTest</div></li><li><div>org.apache.zeppelin.socket.NotebookServerTest.org.apache.zeppelin.socket.NotebookServerTest</div></li><li><div>org.apache.zeppelin.helium.HeliumApplicationFactoryTest.testInterpreterUnbindOfNullReplParagraph</div></li><li><div>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testYarnClusterMode</div></li><li><div>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testLocalMode</div></li><li><div>org.apache.zeppelin.interpreter.SparkInterpreterModeTest.testYarnClientMode</div></li><li><div>org.apache.zeppelin.notebook.NotebookTest.testPerNoteSessionInterpreter</div></li></ol></td><td><ol><li><div>org.apache.zeppelin.spark.PySparkInterpreterTest.testCompletion</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[3]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[3]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[3]</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div></td></tr></tbody></table></div><div style="display:none" id="zookeeperpipe" name="data"><h2><center>ZOOKEEPER</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th width="10%"></th><th>PPC</th><th>X86</th></tr><tr><td>Summary</td><td><div>Total Count : 1130</div><div>Failed Count : 0</div><div>Skipped Count : 1</div><div>Duration : 1 hr 51 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 722ba9409a44a35d287aac803813f508cff2420a</div><div>Last Run: 5 days, 22 hr</div></td><td><div>Total Count : 1130</div><div>Failed Count : 1</div><div>Skipped Count : 1</div><div>Duration : 1 hr 4 min</div><div>Branch Details: refs/remotes/origin/master</div><div>Last Revision: 722ba9409a44a35d287aac803813f508cff2420a</div><div>Last Run: 5 days, 22 hr</div></td></tr><tr><td>Result</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px; "></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol></ol></td><td><ol><div><li>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</li></div></ol></td></tr><tr><td>Description</td><td><ol></ol></td><td><ol><div><li>expected:&lt;NodeDataChanged&gt; but was:&lt;NodeDeleted&gt;</li></div></ol></td></tr><tr><td>Unique Failures</td><td><ol></ol></td><td><ol><li><div>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</div></li></ol></td></tr><tr><td>Last 5 Builds</td><td><div>SUCCESS</div><div>UNSTABLE</div><div>UNSTABLE</div><div>SUCCESS</div><div>SUCCESS</div></td><td><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>UNSTABLE</div><div>SUCCESS</div></td></tr></tbody></table></div><div style="display:block" id="ppc" name="summary"><h2><center>PPC SUMMARY</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th>Package Name</th><th>Result</th><th>Failed Count</th><th>Unique Count</th></tr><tr><td><a href="#" id="anchor_accumulopipe" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_ambaripipe" onclick="showme(this.id);">AMBARI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/aborted.png" align="top" style="width: 16px; height: 16px;"></img>ABORTED</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_atlaspipe" onclick="showme(this.id);">ATLAS</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_falconpipe" onclick="showme(this.id);">FALCON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>4</td><td>4</td></tr><tr><td><a href="#" id="anchor_flumepipe" onclick="showme(this.id);">FLUME</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-lzo" onclick="showme(this.id);">HADOOP-LZO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-master" onclick="showme(this.id);">HADOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>17</td><td>3</td></tr><tr><td><a href="#" id="anchor_hbasepipe" onclick="showme(this.id);">HBASE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>1</td></tr><tr><td><a href="#" id="anchor_hivepipe" onclick="showme(this.id);">HIVE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>14</td><td>3</td></tr><tr><td><a href="#" id="anchor_kafkapipe" onclick="showme(this.id);">KAFKA</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>1</td></tr><tr><td><a href="#" id="anchor_knoxpipe" onclick="showme(this.id);">KNOX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_metronpipe" onclick="showme(this.id);">METRON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_nifi-master" onclick="showme(this.id);">NIFI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_ooziepipe" onclick="showme(this.id);">OOZIE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>33</td><td>33</td></tr><tr><td><a href="#" id="anchor_phoenixpipe" onclick="showme(this.id);">PHOENIX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_pigpipe" onclick="showme(this.id);">PIG</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>20</td><td>0</td></tr><tr><td><a href="#" id="anchor_rangerpipe" onclick="showme(this.id);">RANGER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_sliderpipe" onclick="showme(this.id);">SLIDER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>24</td><td>0</td></tr><tr><td><a href="#" id="anchor_sparkpipe" onclick="showme(this.id);">SPARK</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>0</td></tr><tr><td><a href="#" id="anchor_sqooppipe" onclick="showme(this.id);">SQOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_stormpipe" onclick="showme(this.id);">STORM</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_tezpipe" onclick="showme(this.id);">TEZ</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>0</td></tr><tr><td><a href="#" id="anchor_zeppelinpipe" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>26</td><td>8</td></tr><tr><td><a href="#" id="anchor_zookeeperpipe" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr></tbody></table></div><div style="display:none" id="x86" name="summary"><h2><center>X86 SUMMARY</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th>Package Name</th><th>Result</th><th>Failed Count</th><th>Unique Count</th></tr><tr><td><a href="#" id="anchor_accumulopipe" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>2</td><td>2</td></tr><tr><td><a href="#" id="anchor_ambaripipe" onclick="showme(this.id);">AMBARI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_atlaspipe" onclick="showme(this.id);">ATLAS</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_falconpipe" onclick="showme(this.id);">FALCON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>2</td><td>2</td></tr><tr><td><a href="#" id="anchor_flumepipe" onclick="showme(this.id);">FLUME</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-lzo" onclick="showme(this.id);">HADOOP-LZO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-master" onclick="showme(this.id);">HADOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>421</td><td>407</td></tr><tr><td><a href="#" id="anchor_hbasepipe" onclick="showme(this.id);">HBASE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>3</td><td>3</td></tr><tr><td><a href="#" id="anchor_hivepipe" onclick="showme(this.id);">HIVE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>11</td><td>0</td></tr><tr><td><a href="#" id="anchor_kafkapipe" onclick="showme(this.id);">KAFKA</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_knoxpipe" onclick="showme(this.id);">KNOX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_metronpipe" onclick="showme(this.id);">METRON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_nifi-master" onclick="showme(this.id);">NIFI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_ooziepipe" onclick="showme(this.id);">OOZIE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>4</td><td>4</td></tr><tr><td><a href="#" id="anchor_phoenixpipe" onclick="showme(this.id);">PHOENIX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_pigpipe" onclick="showme(this.id);">PIG</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>20</td><td>0</td></tr><tr><td><a href="#" id="anchor_rangerpipe" onclick="showme(this.id);">RANGER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_sliderpipe" onclick="showme(this.id);">SLIDER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>24</td><td>0</td></tr><tr><td><a href="#" id="anchor_sparkpipe" onclick="showme(this.id);">SPARK</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>0</td></tr><tr><td><a href="#" id="anchor_sqooppipe" onclick="showme(this.id);">SQOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_stormpipe" onclick="showme(this.id);">STORM</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>1</td></tr><tr><td><a href="#" id="anchor_tezpipe" onclick="showme(this.id);">TEZ</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>3</td><td>2</td></tr><tr><td><a href="#" id="anchor_zeppelinpipe" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>31</td><td>13</td></tr><tr><td><a href="#" id="anchor_zookeeperpipe" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>1</td></tr></tbody></table></div><div style="display:none" id="ppcx86" name="summary"><h2><center>FULL SUMMARY</center></h2><table cellpadding="0" width="100%" border="1" cellspacing="0"><tbody><tr><th></th><th colspan="2">Result</th><th colspan="2">Failed Count</th><th colspan="2">Unique Count</th></tr><tr><th>Package Name</th><th>PPC</th><th>X86</th><th>PPC</th><th>X86</th><th>PPC</th><th>X86</th></tr><tr><td><a href="#" id="anchor_accumulopipe" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>0</td><td>2</td><td>0</td><td>2</td></tr><tr><td><a href="#" id="anchor_ambaripipe" onclick="showme(this.id);">AMBARI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/aborted.png" align="top" style="width: 16px; height: 16px;"></img>ABORTED</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_atlaspipe" onclick="showme(this.id);">ATLAS</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_falconpipe" onclick="showme(this.id);">FALCON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>4</td><td>2</td><td>4</td><td>2</td></tr><tr><td><a href="#" id="anchor_flumepipe" onclick="showme(this.id);">FLUME</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-lzo" onclick="showme(this.id);">HADOOP-LZO</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_hadoop-master" onclick="showme(this.id);">HADOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>17</td><td>421</td><td>3</td><td>407</td></tr><tr><td><a href="#" id="anchor_hbasepipe" onclick="showme(this.id);">HBASE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>3</td><td>1</td><td>3</td></tr><tr><td><a href="#" id="anchor_hivepipe" onclick="showme(this.id);">HIVE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>14</td><td>11</td><td>3</td><td>0</td></tr><tr><td><a href="#" id="anchor_kafkapipe" onclick="showme(this.id);">KAFKA</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td><a href="#" id="anchor_knoxpipe" onclick="showme(this.id);">KNOX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_metronpipe" onclick="showme(this.id);">METRON</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_nifi-master" onclick="showme(this.id);">NIFI</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_ooziepipe" onclick="showme(this.id);">OOZIE</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>33</td><td>4</td><td>33</td><td>4</td></tr><tr><td><a href="#" id="anchor_phoenixpipe" onclick="showme(this.id);">PHOENIX</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_pigpipe" onclick="showme(this.id);">PIG</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>20</td><td>20</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_rangerpipe" onclick="showme(this.id);">RANGER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_sliderpipe" onclick="showme(this.id);">SLIDER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>24</td><td>24</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_sparkpipe" onclick="showme(this.id);">SPARK</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_sqooppipe" onclick="showme(this.id);">SQOOP</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td><a href="#" id="anchor_stormpipe" onclick="showme(this.id);">STORM</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>0</td><td>1</td><td>0</td><td>1</td></tr><tr><td><a href="#" id="anchor_tezpipe" onclick="showme(this.id);">TEZ</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>1</td><td>3</td><td>0</td><td>2</td></tr><tr><td><a href="#" id="anchor_zeppelinpipe" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>26</td><td>31</td><td>8</td><td>13</td></tr><tr><td><a href="#" id="anchor_zookeeperpipe" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="https://builds.apache.org/static/53471590/images/48x48/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="https://builds.apache.org/static/53471590/images/48x48/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>0</td><td>1</td><td>0</td><td>1</td></tr></tbody></table></div></div></body></html>
